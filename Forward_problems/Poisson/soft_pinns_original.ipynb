{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T13:11:46.602713Z",
     "start_time": "2024-12-27T13:11:45.379439Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "from pyDOE import lhs\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "#from models_all import *\n",
    "from utils_training import *\n",
    "\n",
    "#Paper reproduction\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T13:11:51.176506Z",
     "start_time": "2024-12-27T13:11:46.605067Z"
    }
   },
   "outputs": [],
   "source": [
    "N_train = 2000\n",
    "N_bound = 100\n",
    "\n",
    "la = np.array([1,1])\n",
    "lb = np.array([0,0])\n",
    "\n",
    "#x,y\n",
    "X_train = lb+(la-lb)*lhs(2,N_train)\n",
    "x_inside = X_train[:,0:1]\n",
    "y_inside = X_train[:,1:2]\n",
    "\n",
    "x_inside = numpy_to_tensor(x_inside, var_name=\"x_inside\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = True)\n",
    "y_inside = numpy_to_tensor(y_inside, var_name=\"y_inside\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = True)\n",
    "\n",
    "data_bound_x0 = np.hstack((np.zeros((N_bound, 1)), lb[1] + (la[1] - lb[1]) * lhs(1, N_bound)))\n",
    "data_bound_x1 = np.hstack((np.ones((N_bound, 1)), lb[1] + (la[1] - lb[1]) * lhs(1, N_bound)))\n",
    "\n",
    "data_bound_y0 = np.hstack((lb[0] + (la[0] - lb[0]) * lhs(1, N_bound), np.zeros((N_bound, 1))))\n",
    "data_bound_y1 = np.hstack((lb[0] + (la[0] - lb[0]) * lhs(1, N_bound), np.ones((N_bound, 1))))\n",
    "\n",
    "data_bound = np.vstack((data_bound_x0, data_bound_x1, data_bound_y0, data_bound_y1))\n",
    "data_bound = numpy_to_tensor(data_bound, var_name=\"data_bound\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T13:11:51.183535Z",
     "start_time": "2024-12-27T13:11:51.179907Z"
    }
   },
   "outputs": [],
   "source": [
    "def exact_u(x, y):\n",
    "    return (1 / (2 * np.pi**2)) * np.sin(np.pi * x) * np.sin(np.pi * y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T13:11:51.387066Z",
     "start_time": "2024-12-27T13:11:51.185405Z"
    }
   },
   "outputs": [],
   "source": [
    "plot_data = np.concatenate((np.linspace(0,1,200).reshape(-1,1),np.linspace(0,1,200).reshape(-1,1)),1)\n",
    "\n",
    "plot_data_x = plot_data[:,0:1]\n",
    "plot_data_y = plot_data[:,1:2]\n",
    "\n",
    "plot_data_X,plot_data_Y = np.meshgrid(plot_data_x,plot_data_y)\n",
    "plot_data_numpy = np.concatenate((plot_data_X.reshape(-1,1),plot_data_Y.reshape(-1,1)),1)\n",
    "\n",
    "plot_data_tensor = torch.from_numpy(plot_data_numpy).float()\n",
    "plot_data_tensor = plot_data_tensor.cuda()\n",
    "\n",
    "aa = exact_u(plot_data_numpy[:,0],plot_data_numpy[:,1])\n",
    "plt.imshow(aa.reshape(200,200), interpolation='nearest',extent=[0, 1, 0, 1], cmap='rainbow')\n",
    "plt.colorbar(shrink=.98)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T13:11:51.398716Z",
     "start_time": "2024-12-27T13:11:51.388931Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(5678)\n",
    "n_test_data = 1000\n",
    "\n",
    "test_data = lb+(la-lb)*lhs(2,n_test_data)\n",
    "test_u = exact_u(test_data[:,0:1], test_data[:,1:2])\n",
    "\n",
    "test_data = numpy_to_tensor(test_data, var_name=\"test_data\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = False)\n",
    "test_u = numpy_to_tensor(test_u, var_name=\"test_u\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T13:11:51.405749Z",
     "start_time": "2024-12-27T13:11:51.400681Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_loss_f(x_grad, y_grad, PINNs, return_sequence='not'):\n",
    "    \n",
    "    ########### loss f  ###########\n",
    "    E_inside = PINNs1(torch.cat((x_grad,y_grad),1))\n",
    "    \n",
    "    E_x = compute_higher_order_derivatives(E_inside, [x_grad])\n",
    "    E_xx = compute_higher_order_derivatives(E_x, [x_grad])  \n",
    "    E_y = compute_higher_order_derivatives(E_inside, [y_grad])\n",
    "    E_yy = compute_higher_order_derivatives(E_y, [y_grad])\n",
    "    \n",
    "    deata_E = E_xx+E_yy\n",
    "    \n",
    "    loss_term = deata_E+torch.sin(torch.tensor(np.pi)*x_grad)*torch.sin(torch.tensor(np.pi)*y_grad)\n",
    "    ########### loss f  ###########\n",
    "    \n",
    "    if return_sequence=='yes':\n",
    "        return torch.square(loss_term)\n",
    "    else:\n",
    "        return torch.mean(torch.square(loss_term))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loss_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T13:11:51.413041Z",
     "start_time": "2024-12-27T13:11:51.407528Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_loss_bound(bound_x, bound_y, PINNs, return_sequence='not'):\n",
    "\n",
    "    E_bound_x_0 = PINNs1(torch.cat((bound_x,torch.zeros_like(bound_x)),1))\n",
    "    E_bound_x_1 = PINNs1(torch.cat((bound_x,torch.ones_like(bound_x)),1))\n",
    "    \n",
    "    E_bound_y_0 = PINNs1(torch.cat((torch.zeros_like(bound_y),bound_y),1))\n",
    "    E_bound_y_1 = PINNs1(torch.cat((torch.ones_like(bound_y),bound_y),1))\n",
    "    \n",
    "    loss_bound_for_bound_x_0 = torch.mean(torch.square(E_bound_x_0))\n",
    "    loss_bound_for_bound_x_1 = torch.mean(torch.square(E_bound_x_1))\n",
    "    \n",
    "    loss_bound_for_bound_y_0 = torch.mean(torch.square(E_bound_y_0))\n",
    "    loss_bound_for_bound_y_1 = torch.mean(torch.square(E_bound_y_1))\n",
    "    \n",
    "    loss_bound_value = loss_bound_for_bound_x_0+loss_bound_for_bound_x_1+loss_bound_for_bound_y_0+loss_bound_for_bound_y_1\n",
    "    \n",
    "    return loss_bound_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T13:11:51.419330Z",
     "start_time": "2024-12-27T13:11:51.415061Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(\"Using CUDA on GPU\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T13:11:51.426644Z",
     "start_time": "2024-12-27T13:11:51.423420Z"
    }
   },
   "outputs": [],
   "source": [
    "#Paper reproduction\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T13:11:51.437836Z",
     "start_time": "2024-12-27T13:11:51.428564Z"
    }
   },
   "outputs": [],
   "source": [
    "class hidden_layers(nn.Module):\n",
    "    def __init__(self,input_number,output_number):\n",
    "        super(hidden_layers, self).__init__()\n",
    "        self.layer = nn.Linear(input_number,output_number)\n",
    "    def forward(self, x):\n",
    "        x = self.layer(x)\n",
    "        x = torch.tanh(x)\n",
    "        return x\n",
    "\n",
    "class NN_H2 (nn.Module):\n",
    "    def __init__(self,in_N, width, depth, out_N):\n",
    "        super(NN_H2, self).__init__()\n",
    "        self.in_N = in_N\n",
    "        self.width = width\n",
    "        self.depth = depth\n",
    "        self.out_N = out_N\n",
    "\n",
    "        self.stack = nn.ModuleList()\n",
    "\n",
    "        self.stack.append(hidden_layers(in_N, width))\n",
    "\n",
    "        for i in range(depth):\n",
    "            self.stack.append(hidden_layers(width, width))\n",
    "\n",
    "        self.stack.append(nn.Linear(width, out_N))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        for m in self.stack:\n",
    "            x = m(x)\n",
    "        return x\n",
    "\n",
    "def weights_init(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.Conv2d):\n",
    "        #nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
    "        nn.init.xavier_normal_(m.weight)\n",
    "        nn.init.constant_(m.bias, 0)\n",
    "    elif isinstance(m, nn.BatchNorm2d):\n",
    "        nn.init.constant_(m.weight, 1)\n",
    "        nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T13:11:51.458790Z",
     "start_time": "2024-12-27T13:11:51.439834Z"
    }
   },
   "outputs": [],
   "source": [
    "PINNs1 = NN_H2(2, 20, 4, 1)\n",
    "PINNs1.apply(weights_init)\n",
    "PINNs1.cuda()\n",
    "\n",
    "optimizer1 = optim.Adam(PINNs1.parameters(), lr=0.001,betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T13:11:51.464800Z",
     "start_time": "2024-12-27T13:11:51.460815Z"
    }
   },
   "outputs": [],
   "source": [
    "##############PW_L_f###############\n",
    "e_k = 1e-4\n",
    "q_k = 0.01\n",
    "s_k = 0.3\n",
    "Ada_CL_L_f = Ada_CL(e_k,q_k,s_k,device)\n",
    "weight_sequence_L_f = (1/N_train)*np.ones((N_train,1))\n",
    "##############PW_L_f###############\n",
    "\n",
    "\n",
    "########### record list ###########\n",
    "loss_all_1 = []\n",
    "loss_f_1 = []\n",
    "loss_b_1 = []\n",
    "test_loss_1 = []\n",
    "plot_abs_loss = []\n",
    "beta_number_list = []\n",
    "########### record list ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-27T13:12:30.694452Z",
     "start_time": "2024-12-27T13:11:51.467197Z"
    }
   },
   "outputs": [],
   "source": [
    "nIter1 = 2000\n",
    "it = 0\n",
    "\n",
    "while  it<2000:\n",
    "    \n",
    "    ##### loss bound  ######\n",
    "    E_bound = PINNs1(data_bound)\n",
    "    loss_bound = torch.mean(torch.square(E_bound))\n",
    "    \n",
    "    ##############PW_L_f###############\n",
    "    loss_f = get_loss_f(x_inside,y_inside,PINNs1,return_sequence='not')\n",
    "    ##############PW_L_f###############\n",
    "    \n",
    "    #########loss PI#########\n",
    "    loss = loss_f+3*loss_bound\n",
    "    #########loss PI#########\n",
    "    \n",
    "    #########  test_loss NRMSE  #########\n",
    "    pre_u = PINNs1(test_data)  \n",
    "    test_loss = relative_l2_torch(pre_u,test_u)\n",
    "    test_loss_1.append(test_loss)\n",
    "    #########  test_loss NRMSE  #########\n",
    "    \n",
    "    ##############Record###############\n",
    "    loss_all_1.append(loss.item())\n",
    "    loss_f_1.append(loss_f.item())\n",
    "    loss_b_1.append(loss_bound.item())\n",
    "    \n",
    "    loss_f_sequence = get_loss_f(x_inside,y_inside,PINNs1,return_sequence='yes').cpu().detach().numpy()\n",
    "    beta_number_value = np.ones_like(loss_f_sequence)\n",
    "    beta_number_value = np.sum(beta_number_value[loss_f_sequence>e_k])/N_train\n",
    "    beta_number_list.append(beta_number_value)              \n",
    "    ##############Record Original###############\n",
    "    \n",
    "    \n",
    "    if it%20 == 0 and it<2000:\n",
    "        plot_abs_loss.append(np.abs(aa-PINNs1(plot_data_tensor).cpu().detach().numpy().reshape(-1,)))\n",
    "    \n",
    "    if it % 500 == 0:\n",
    "        print('It:', it, 'train_loss:', loss.item(), 'test_loss:', test_loss)\n",
    "    \n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    it = it + 1        \n",
    "    \n",
    "print('Final:', 'train_loss:', loss.item(), 'test_loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepxde)",
   "language": "python",
   "name": "test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
