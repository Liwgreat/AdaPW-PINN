{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "353a13ed",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T03:18:08.357220Z",
     "start_time": "2024-12-21T03:18:07.200400Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim, autograd\n",
    "from torch.nn import functional as F\n",
    "from pyDOE import lhs\n",
    "import scipy.io\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import matplotlib.gridspec as gridspec\n",
    "%matplotlib inline\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "\n",
    "from utils_training import *\n",
    "\n",
    "#Paper reproduction\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489455b4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T03:18:11.869980Z",
     "start_time": "2024-12-21T03:18:08.360714Z"
    }
   },
   "outputs": [],
   "source": [
    "N_train = 10000\n",
    "N_bound = 200\n",
    "\n",
    "# x,t\n",
    "la = np.array([1,1])\n",
    "lb = np.array([-1,0])\n",
    "\n",
    "traindata = lb+(la-lb)*lhs(2,N_train)\n",
    "x_inside = traindata[:,0:1]\n",
    "t_inside = traindata[:,1:2]\n",
    "\n",
    "x_inside = numpy_to_tensor(x_inside, var_name=\"x_inside\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = True)\n",
    "t_inside = numpy_to_tensor(t_inside, var_name=\"t_inside\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = True)\n",
    "\n",
    "x_bound = lb[0]+(la[0]-lb[0])*lhs(1,N_bound)\n",
    "t_bound = lb[1]+(la[1]-lb[1])*lhs(1,N_bound)\n",
    "\n",
    "x_bound = numpy_to_tensor(x_bound, var_name=\"x_bound\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = False)\n",
    "t_bound = numpy_to_tensor(t_bound, var_name=\"t_bound\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "189cc41c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T03:18:11.879948Z",
     "start_time": "2024-12-21T03:18:11.874530Z"
    }
   },
   "outputs": [],
   "source": [
    "import scipy.io\n",
    "data = scipy.io.loadmat('./burgers_shock.mat')\n",
    "\n",
    "t_exact = data['t'].reshape(-1,1)\n",
    "\n",
    "x_exact = data['x'].reshape(-1,1)\n",
    "\n",
    "Exact_u = np.real(data['usol']).T\n",
    "\n",
    "print('t_exact:',t_exact.shape)\n",
    "print('x_exact:',x_exact.shape)\n",
    "print('Exact_u:',Exact_u.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b76212",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T03:18:11.888243Z",
     "start_time": "2024-12-21T03:18:11.882449Z"
    }
   },
   "outputs": [],
   "source": [
    "X_exact, T_exact = np.meshgrid(x_exact,t_exact)\n",
    "print('X_exact:',X_exact.shape)\n",
    "print('T_exact:',T_exact.shape)\n",
    "\n",
    "X_exact_flatten = X_exact.flatten()[:,None]\n",
    "T_exact_flatten = T_exact.flatten()[:,None]\n",
    "data_star = np.hstack((X_exact_flatten,T_exact_flatten))\n",
    "u_star = Exact_u.flatten()[:,None] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bedf6f64",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T03:18:11.896844Z",
     "start_time": "2024-12-21T03:18:11.890977Z"
    }
   },
   "outputs": [],
   "source": [
    "data_star.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "989099b6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T03:18:11.916483Z",
     "start_time": "2024-12-21T03:18:11.899492Z"
    }
   },
   "outputs": [],
   "source": [
    "X_star = numpy_to_tensor(data_star, var_name=\"X_star\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf85a03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T03:18:11.937543Z",
     "start_time": "2024-12-21T03:18:11.922123Z"
    }
   },
   "outputs": [],
   "source": [
    "X_star"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc21247d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T03:18:11.954256Z",
     "start_time": "2024-12-21T03:18:11.939877Z"
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(5678)\n",
    "n_test_data = 10000\n",
    "\n",
    "index_t = (lhs(1,n_test_data))*len(t_exact)\n",
    "index_t = np.floor(index_t).reshape(n_test_data,).astype(int)\n",
    "observe_t = t_exact[index_t]\n",
    "\n",
    "index_x = (lhs(1,n_test_data))*len(x_exact)\n",
    "index_x = np.floor(index_x).reshape(n_test_data,).astype(int)\n",
    "observe_x = x_exact[index_x]\n",
    "\n",
    "test_data = np.hstack((observe_x,observe_t))\n",
    "test_u = Exact_u[index_t,index_x].reshape(-1,1)\n",
    "\n",
    "test_data = numpy_to_tensor(test_data, var_name=\"test_data\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = True)\n",
    "test_u = numpy_to_tensor(test_u, var_name=\"test_u\", value_range_dim = True, to_torch = True, to_cuda = True, requires_grad = True)\n",
    "\n",
    "test_data_x_inside = test_data[:,0:1]\n",
    "test_data_t_inside = test_data[:,1:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d0b743",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T03:18:11.965019Z",
     "start_time": "2024-12-21T03:18:11.958247Z"
    }
   },
   "outputs": [],
   "source": [
    "test_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "764ba955",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T03:18:11.970819Z",
     "start_time": "2024-12-21T03:18:11.967345Z"
    }
   },
   "outputs": [],
   "source": [
    "def output_transform(x, y):\n",
    "    x_in = x[:, 0:1]\n",
    "    t_in = x[:, 1:2]\n",
    "\n",
    "    return (1 - x_in) * (1 + x_in) * (1 - torch.exp(-t_in)) * y - torch.sin(np.pi * x_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f835e3a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-05-04T08:29:49.730175Z",
     "start_time": "2024-05-04T08:29:49.723076Z"
    }
   },
   "source": [
    "## Loss_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85831e94",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T03:18:11.982519Z",
     "start_time": "2024-12-21T03:18:11.975095Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_loss_f(x_grad, t_grad, PINNs, C, return_sequence='not'):\n",
    "    \n",
    "    ########### loss f  ###########\n",
    "    E_inside = PINNs(torch.cat((x_grad,t_grad),1))\n",
    "    #E_inside = output_transform(torch.cat((x_grad,y_grad),axis=1), E_inside)\n",
    "\n",
    "    E_x = compute_higher_order_derivatives(E_inside, [x_grad])\n",
    "    E_xx = compute_higher_order_derivatives(E_x, [x_grad])  \n",
    "    E_t = compute_higher_order_derivatives(E_inside, [t_grad])\n",
    "    \n",
    "    loss_term = E_t+E_inside*E_x-C1*E_xx\n",
    "    ########### loss f  ###########\n",
    "    \n",
    "    if return_sequence == 'yes':\n",
    "        return torch.square(loss_term)\n",
    "    else:\n",
    "        return torch.mean(torch.square(loss_term))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf1e374",
   "metadata": {},
   "source": [
    "## loss_bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55a14876",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T03:18:11.992175Z",
     "start_time": "2024-12-21T03:18:11.985251Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_loss_bound(bound_x, bound_t, PINNs, C, return_sequence='not'):\n",
    "\n",
    "    E_bound = PINNs1(torch.cat((bound_x,torch.zeros_like(bound_x)),1))\n",
    "    real_bound = -torch.sin(torch.tensor(np.pi)*bound_x)\n",
    "    \n",
    "    loss_bound_for_a = torch.mean(torch.square(E_bound-real_bound))\n",
    "    \n",
    "    loss_bound_for_b = torch.mean(torch.square(PINNs1(torch.cat((torch.ones_like(bound_t),bound_t),1))))\n",
    "    \n",
    "    loss_bound_for_c = torch.mean(torch.square(PINNs1(torch.cat((-torch.ones_like(bound_t),bound_t),1))))\n",
    "    \n",
    "    loss_bound_value = loss_bound_for_a+loss_bound_for_b+loss_bound_for_c\n",
    "    \n",
    "    return loss_bound_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7878c2d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T03:18:11.998963Z",
     "start_time": "2024-12-21T03:18:11.994768Z"
    }
   },
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = \"cuda\"\n",
    "    print(\"Using CUDA on GPU\")\n",
    "else:\n",
    "    device = \"cpu\"\n",
    "    print(\"Using CPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154b97b0",
   "metadata": {},
   "source": [
    "# PINN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "77c545cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T03:18:12.005553Z",
     "start_time": "2024-12-21T03:18:12.001812Z"
    }
   },
   "outputs": [],
   "source": [
    "#Paper reproduction\n",
    "torch.manual_seed(1234)\n",
    "torch.cuda.manual_seed(1234)\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98763605",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T03:18:12.018833Z",
     "start_time": "2024-12-21T03:18:12.008354Z"
    }
   },
   "outputs": [],
   "source": [
    "net_settings_for_PINNs1 = NetSetting(input_dims=2, hidden_neurons_list=[20]*8, \n",
    "                                     output_dims=1, hidden_activation='tanh', \n",
    "                                     output_activation=None, initializer_method='xavier')\n",
    "PINNs1 = get_mlp_pinn(net_settings_for_PINNs1)\n",
    "PINNs1.cuda() \n",
    "\n",
    "initialize_weights(PINNs1, net_settings_for_PINNs1.initializer_method)\n",
    "\n",
    "optimizer1 = optim.Adam(PINNs1.parameters(), lr=0.001,betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbb52018",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T03:18:12.027071Z",
     "start_time": "2024-12-21T03:18:12.020900Z"
    }
   },
   "outputs": [],
   "source": [
    "##############PW_L_f###############\n",
    "# e_k = 0.001\n",
    "# q_k = 0.00005\n",
    "# s_k = 0.5\n",
    "e_k = 0.0005\n",
    "q_k = 0.00005\n",
    "s_k = 0.7\n",
    "Ada_CL_L_f = Ada_CL(e_k,q_k,s_k,device)\n",
    "weight_sequence_L_f = (1/N_train)*np.ones((N_train,1))\n",
    "##############PW_L_f###############   \n",
    "\n",
    "\n",
    "############## plot L_f list ###############  \n",
    "plot_loss_f_list = []\n",
    "X_star_x = X_star[:,0:1]\n",
    "X_star_t = X_star[:,1:2]\n",
    "X_star_x.requires_grad_()\n",
    "X_star_t.requires_grad_()\n",
    "############## plot L_f list ###############  \n",
    "\n",
    "############## Record list ###############\n",
    "loss_all_1 = []\n",
    "loss_all_2 = []\n",
    "loss_f_1 = []\n",
    "loss_f_2 = []\n",
    "loss_b_1 = []\n",
    "test_loss_1 = []\n",
    "beta_number_list = []\n",
    "rho_k_list = []\n",
    "\n",
    "loss_f_sequence_list = []\n",
    "weight_sequence_L_f_list = []\n",
    "plot_heat_list = []\n",
    "############## Record list ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9f5c2e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-21T03:26:18.944043Z",
     "start_time": "2024-12-21T03:18:12.029584Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "C1 = 0.01/np.pi\n",
    "\n",
    "nIter1 = 20000\n",
    "it = 0\n",
    "\n",
    "while it<20000:\n",
    "    \n",
    "    ##### loss bound  ######\n",
    "    loss_bound = get_loss_bound(x_bound, t_bound, PINNs1, C1, return_sequence='not')\n",
    "\n",
    "    ##############PW_L_f###############\n",
    "    loss_f_sequence = get_loss_f(x_inside,t_inside,PINNs1,C1,return_sequence='yes')\n",
    "    loss_f,weight_sequence_L_f,rho_k,beta_sequence = Ada_CL_L_f.Training_Scheduler_torch(loss_f_sequence, \n",
    "                                                                                         weight_sequence_L_f,\n",
    "                                                                                         alpha_k_function = 'default',\n",
    "                                                                                         record = 'yes')\n",
    "    beta_number_list.append(np.sum(beta_sequence)/N_train)\n",
    "    rho_k_list.append(rho_k)\n",
    "    ##############PW_L_f###############    \n",
    "    \n",
    "    #########loss PI#########\n",
    "    loss = loss_f+loss_bound\n",
    "   \n",
    "    #########  test_loss NRMSE  #########\n",
    "    pre_u = PINNs1(test_data)  \n",
    "    test_loss = relative_l2_torch(pre_u,test_u)\n",
    "    #########  test_loss NRMSE  #########\n",
    "    \n",
    "    ##############Record###############\n",
    "    test_loss_1.append(test_loss)    \n",
    "    loss_all_2.append(loss.item())\n",
    "    loss_f_2.append(loss_f.item())\n",
    "    loss_b_1.append(loss_bound.item())   \n",
    "    ##############Record###############\n",
    "    \n",
    "    ##############Record Original###############\n",
    "    loss_f_original = get_loss_f(x_inside,t_inside,PINNs1,C1,return_sequence='not')\n",
    "    loss_all_original = loss_f_original+loss_bound\n",
    "    loss_all_1.append(loss_all_original.item())\n",
    "    loss_f_1.append(loss_f_original.item())                 \n",
    "    ##############Record Original###############\n",
    "    \n",
    "    if it % 1000 == 0:\n",
    "        plot_loss_f_list.append(get_loss_f(X_star_x,X_star_t,PINNs1,C1,return_sequence='yes').cpu().detach().numpy())\n",
    "        loss_f_sequence_list.append(loss_f_sequence.cpu().detach().numpy())\n",
    "        weight_sequence_L_f_list.append(weight_sequence_L_f)\n",
    "        plot_heat_list.append(PINNs1(X_star).cpu().detach().numpy())\n",
    "        print('It:', it, 'train_loss:', loss.item(), 'test_loss:', test_loss) \n",
    "\n",
    "    optimizer1.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer1.step()\n",
    "    \n",
    "    it = it + 1   \n",
    "\n",
    "print('Final:', 'train_loss:', loss.item(), 'test_loss:', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24892cb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25356dbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (deepxde)",
   "language": "python",
   "name": "test2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "256px"
   },
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
